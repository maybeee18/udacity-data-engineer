### [Project 1: Data Modeling with Postgres](/1-data-modeling-with-postgres/)

You will need to define fact and dimension tables for a star schema for a particular analytic focus, and write an ETL 
pipeline that transfers data from files in two local directories into these tables in Postgres using Python and SQL.

### [Project 2: Data Modeling with Apache Cassandra](/2-data-modeling-with-cassandra/)

You will need to model fact and dimension tables for a star schema for a particular analytic focus, and write an ETL 
pipeline that transfers CSV files from two local directories into Apache Cassandra tables using Python and SQL.

### [Project 3: Data Warehouse](/3-data-warehouse/)

You will need to model fact and dimension tables for a star schema for a particular analytic focus, and write an ETL 
pipeline that transfers JSON files from two S3 into Amazon Redshift tables using Python, SQL and boto3.
