# Udacity Data Engineer Nanodegree Projects

![](img/cover.jpg)

## [Project 1: Data Modeling with Postgres](/1-data-modeling-with-postgres/)

You will need to define fact and dimension tables for a star schema for a
particular analytic focus, and write an ETL pipeline that transfers data from
files in two local directories into these tables in Postgres using Python and SQL.

## [Project 2: Data Modeling with Apache Cassandra](/2-data-modeling-with-cassandra/)

You will need to model fact and dimension tables for a star schema for a particular
analytic focus, and write an ETL pipeline that transfers CSV files from two local
directories into Apache Cassandra tables using Python and SQL.

## [Project 3: Data Warehouse in AWS](/3-data-warehouse/)

You will need to model fact and dimension tables for a star schema for a
particular analytic focus, and write an ETL pipeline that transfers JSON files
from two S3 into Amazon Redshift tables using Python, SQL and boto3.

## [Project 4: Data Lake in AWS](/4-data-lake/)

In this project, you need to build an ETL pipeline for a data lake hosted on S3.
You will need to load data from S3, process the data into analytics tables using
Spark, and load them back into S3. Deployment of this Spark process on a cluster
using AWS EMR is part of the job.

## [Project 5: Data pipelines with Airflow](/5-data-pipelines-airflow/)

You will need to create your own custom operators to perform tasks such as
staging the data, filling the data warehouse, and running checks on the data as
the final step. You going to work with Airflow, S3 and Redshift cluster.

## [Project 6: Capstone Project - NOAA Climate Data Dashboard](/6-capstone-project/)

In this project I decided to build climate analysis dashboard based on this
[Kaggle](https://www.kaggle.com/noaa/noaa-global-surface-summary-of-the-day)
dataset using Docker, Influx DB and Grafana.
